import os
import numpy as np
import torch
import cv2
from typing import Dict, Tuple, List, Union, Optional

# MiDaSæ·±åº¦ä¼°è¨ˆ
import torch.nn.functional as F
from torch.utils.model_zoo import load_url

# ç”¨æ–¼å¹³é¢æª¢æ¸¬çš„å·¥å…·
from skimage import measure
import yaml


from modules.midas_utils import load_model


class DepthEstimator:
    """ä½¿ç”¨MiDaSé€²è¡Œå–®å¼µåœ–åƒæ·±åº¦ä¼°è¨ˆ"""

    def __init__(self, config: Dict):
        self.config = config
        self.device = torch.device(config['device'])

        model_type = config['model_type']
        model_path = config['model_path']

        print(f"ğŸ”§ è¼‰å…¥ MiDaS æ¨¡å‹: {model_type} ...")
        self.model, self.transform = load_model(model_type, self.device)
        print("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")

    def estimate_depth(self, img: np.ndarray) -> np.ndarray:
        input_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255.0
        input_transformed = self.transform(input_image)
        # input_tensor = torch.from_numpy(input_transformed).to(self.device)
        input_tensor = input_transformed.to(self.device)
        with torch.no_grad():
            prediction = self.model(input_tensor)
            prediction = torch.nn.functional.interpolate(
                prediction.unsqueeze(1),
                size=img.shape[:2],
                mode="bicubic",
                align_corners=False,
            ).squeeze(1)

        depth = prediction.squeeze().cpu().numpy()
        # Normalize to 0~1
        depth_min = depth.min()
        depth_max = depth.max()
        depth = (depth - depth_min) / (depth_max - depth_min + 1e-8)

        return depth


class PlaneDetector:
    """å¹³é¢æª¢æ¸¬å’Œåˆ†æ"""
    
    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–å¹³é¢æª¢æ¸¬å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹åƒæ•¸
        """
        self.config = config
        self.device = torch.device(config['device'])
        self.confidence_threshold = config['confidence_threshold']
        
        # æ³¨æ„ï¼šå®Œæ•´çš„PlaneRCNNå¯¦ç¾éœ€è¦å®Œæ•´æ¨¡å‹
        # é€™è£¡ä½¿ç”¨ä¸€å€‹åŸºæ–¼æ·±åº¦åœ–çš„ç°¡åŒ–å¯¦ç¾
        print("Initializing plane detection module...")
        
    def detect_planes(self, img: np.ndarray, depth_map: np.ndarray) -> Tuple[List[Dict], np.ndarray]:
        """
        åŸºæ–¼æ·±åº¦åœ–æª¢æ¸¬å¹³é¢
        
        Args:
            img: åŸå§‹BGRåœ–åƒ (H, W, 3)
            depth_map: æ·±åº¦åœ– (H, W)
            
        Returns:
            - å¹³é¢åˆ—è¡¨ï¼Œæ¯å€‹å¹³é¢æ˜¯ä¸€å€‹å­—å…¸ï¼ŒåŒ…å«maskã€æ³•ç·šå‘é‡ç­‰ä¿¡æ¯
            - å¹³é¢é®ç½©ï¼Œæ¯å€‹åƒç´ å€¼è¡¨ç¤ºè©²é»å±¬æ–¼å“ªå€‹å¹³é¢ID
        """
        # å°æ·±åº¦åœ–é€²è¡Œé‚Šç·£æª¢æ¸¬ï¼Œæ‰¾å‡ºæ·±åº¦ä¸é€£çºŒçš„å€åŸŸ
        depth_edges = cv2.Canny((depth_map * 255).astype(np.uint8), 50, 150)
        
        # å¹³æ»‘æ·±åº¦åœ–ä»¥æ¸›å°‘å™ªéŸ³
        smoothed_depth = cv2.GaussianBlur(depth_map, (5, 5), 0)
        
        # ä½¿ç”¨åˆ†æ°´å¶ºç®—æ³•æˆ–é€£é€šå€åŸŸé€²è¡Œå¹³é¢åˆ†å‰²
        # ç‚ºäº†ç°¡åŒ–ï¼Œé€™è£¡ä½¿ç”¨åŸºæ–¼æ·±åº¦çš„é–¾å€¼åˆ†å‰²
        labels = measure.label(smoothed_depth > 0.5, connectivity=2)
        
        # éæ¿¾å°å€åŸŸ
        unique, counts = np.unique(labels, return_counts=True)
        for label, count in zip(unique, counts):
            if count < 1000:  # éæ¿¾å°æ–¼1000åƒç´ çš„å€åŸŸ
                labels[labels == label] = 0
                
        # é‡æ–°æ¨™è¨˜æ¨™ç±¤ä»¥ç¢ºä¿é€£çºŒ
        labels = measure.label(labels > 0, connectivity=2)
        
        # ç‚ºæ¯å€‹æª¢æ¸¬åˆ°çš„å¹³é¢å‰µå»ºæ•¸æ“šçµæ§‹
        planes = []
        for plane_id in range(1, labels.max() + 1):
            mask = (labels == plane_id).astype(np.uint8)
            
            # è¨ˆç®—å¹³é¢å€åŸŸ
            area = np.sum(mask)
            if area < 5000:  # å¿½ç•¥å¤ªå°çš„å¹³é¢
                continue
                
            # æ‰¾åˆ°å¹³é¢çš„è¼ªå»“
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # è¨ˆç®—å¹³é¢çš„æ³•ç·šå‘é‡ï¼ˆé€™è£¡æ˜¯ç°¡åŒ–å¯¦ç¾ï¼‰
            # åœ¨å¯¦éš›çš„ PlaneRCNN ä¸­ï¼Œæ³•ç·šå‘é‡ä¾†è‡ªæ·±åº¦å­¸ç¿’æ¨¡å‹
            y_indices, x_indices = np.where(mask > 0)
            
            # é€šééš¨æ©Ÿæ¡æ¨£é»ä¾†ä¼°è¨ˆå¹³é¢æ–¹ç¨‹ï¼ˆç°¡åŒ–ï¼‰
            if len(y_indices) > 100:
                # éš¨æ©Ÿé¸æ“‡100å€‹é»
                idx = np.random.choice(len(y_indices), 100, replace=False)
                samples_y, samples_x = y_indices[idx], x_indices[idx]
                depths = depth_map[samples_y, samples_x]
                
                # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•æ“¬åˆå¹³é¢æ–¹ç¨‹ï¼šax + by + cz + d = 0
                # å…¶ä¸­ (a, b, c) æ˜¯æ³•ç·šå‘é‡
                A = np.column_stack([samples_x, samples_y, np.ones(len(samples_x))])
                b = depths
                
                try:
                    # æ±‚è§£æ–¹ç¨‹ Ax = b
                    normal, _, _, _ = np.linalg.lstsq(A, b, rcond=None)
                    # æ³•ç·šå‘é‡æ¨™æº–åŒ–
                    norm = np.sqrt(normal[0]**2 + normal[1]**2 + 1)
                    normal = np.array([normal[0]/norm, normal[1]/norm, 1/norm])
                except:
                    normal = np.array([0, 0, 1])  # é»˜èªå‘ä¸Šçš„æ³•ç·š
            else:
                normal = np.array([0, 0, 1])  # é»˜èªå‘ä¸Šçš„æ³•ç·š
            
            # è¨ˆç®—å¹³é¢çš„ä¸­å¿ƒé»
            center_y, center_x = np.mean(y_indices), np.mean(x_indices)
            center_depth = np.median(depth_map[y_indices, x_indices])
            
            # æ·»åŠ å¹³é¢æ•¸æ“š
            planes.append({
                'id': plane_id,
                'mask': mask,
                'normal': normal,
                'center': (center_x, center_y, center_depth),
                'area': area,
                'contours': contours,
                # æ ¹æ“šå¹³é¢æ³•ç·šæ–¹å‘ä¼°è¨ˆå¹³é¢é¡å‹ (åœ°é¢ã€ç‰†ã€æ¡Œé¢ç­‰)
                'type': 'ground' if normal[2] > 0.8 else ('wall' if normal[2] < 0.3 else 'other')
            })
        
        # å‰µå»ºå½©è‰²æ¨™ç±¤åœ–åƒç”¨æ–¼å¯è¦–åŒ–
        plane_mask = np.zeros_like(labels)
        for plane in planes:
            plane_mask[plane['mask'] > 0] = plane['id']
        
        return planes, plane_mask


class SceneUnderstanding:
    """å ´æ™¯ç†è§£ç¸½æ¨¡çµ„ï¼Œçµåˆæ·±åº¦ä¼°è¨ˆå’Œå¹³é¢æª¢æ¸¬"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–å ´æ™¯ç†è§£æ¨¡çµ„
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
        """
        # è¼‰å…¥é…ç½®
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        # åˆå§‹åŒ–å­æ¨¡çµ„
        self.depth_estimator = DepthEstimator(self.config['models']['midas'])
        self.plane_detector = PlaneDetector(self.config['models']['planercnn'])
        
    def process_frame(self, frame: np.ndarray) -> Dict:
        """
        è™•ç†å–®ä¸€å½±ç‰‡å¹€ï¼Œé€²è¡Œå ´æ™¯ç†è§£
        
        Args:
            frame: BGRæ ¼å¼çš„å½±ç‰‡å¹€
            
        Returns:
            åŒ…å«æ·±åº¦åœ–ã€å¹³é¢ä¿¡æ¯ç­‰çš„å­—å…¸
        """
        print("ğŸ” [1/2] æ­£åœ¨ä¼°è¨ˆæ·±åº¦...")
        depth_map = self.depth_estimator.estimate_depth(frame)
        print("âœ… æ·±åº¦ä¼°è¨ˆå®Œæˆ")

        print("ğŸ” [2/2] æ­£åœ¨åµæ¸¬å¹³é¢...")
        planes, plane_mask = self.plane_detector.detect_planes(frame, depth_map)
        print(f"âœ… å¹³é¢åµæ¸¬å®Œæˆï¼Œå…±åµæ¸¬åˆ° {len(planes)} å€‹å¹³é¢")

        return {
            'depth_map': depth_map,
            'planes': planes,
            'plane_mask': plane_mask,
            'frame_shape': frame.shape
        }

    
    def visualize_results(self, frame: np.ndarray, results: Dict) -> np.ndarray:
        """
        å¯è¦–åŒ–å ´æ™¯ç†è§£çµæœ
        
        Args:
            frame: åŸå§‹å½±ç‰‡å¹€
            results: process_frameè¿”å›çš„çµæœ
            
        Returns:
            å¯è¦–åŒ–åœ–åƒ
        """
        print("ğŸ¨ æ­£åœ¨ç”Ÿæˆå¯è¦–åŒ–åœ–åƒ...")
        # è¤‡è£½åŸå§‹å¹€
        vis_img = frame.copy()
        
        # 1. é¡¯ç¤ºæ·±åº¦åœ–
        depth_colored = cv2.applyColorMap((results['depth_map'] * 255).astype(np.uint8), cv2.COLORMAP_INFERNO)
        depth_vis = cv2.addWeighted(frame, 0.6, depth_colored, 0.4, 0)
        
        # 2. é¡¯ç¤ºå¹³é¢
        plane_vis = frame.copy()
        # ç‚ºæ¯å€‹å¹³é¢ä½¿ç”¨ä¸åŒçš„é¡è‰²
        colors = [
            (0, 0, 255),    # ç´…è‰²
            (0, 255, 0),    # ç¶ è‰²
            (255, 0, 0),    # è—è‰²
            (0, 255, 255),  # é»ƒè‰²
            (255, 0, 255),  # ç´«è‰²
            (255, 255, 0),  # é’è‰²
            (128, 0, 0),    # æš—è—è‰²
            (0, 128, 0),    # æš—ç¶ è‰²
            (0, 0, 128),    # æš—ç´…è‰²
        ]
        
        for i, plane in enumerate(results['planes']):
            color = colors[i % len(colors)]
            # ç¹ªè£½å¹³é¢è¼ªå»“
            cv2.drawContours(plane_vis, plane['contours'], -1, color, 2)
            
            # åœ¨å¹³é¢ä¸­å¿ƒé¡¯ç¤ºIDå’Œé¡å‹
            center = (int(plane['center'][0]), int(plane['center'][1]))
            cv2.putText(
                plane_vis, 
                f"#{plane['id']} {plane['type']}", 
                center,
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
            )
            
            # ç¹ªè£½æ³•ç·šå‘é‡ï¼ˆç°¡å–®å¯è¦–åŒ–ï¼‰
            normal = plane['normal']
            end_point = (
                int(center[0] + normal[0] * 50),
                int(center[1] + normal[1] * 50)
            )
            cv2.arrowedLine(plane_vis, center, end_point, color, 2)
        
        # 3. åˆä½µå¯è¦–åŒ–çµæœ
        h, w = frame.shape[:2]
        vis_combined = np.zeros((h * 2, w, 3), dtype=np.uint8)
        vis_combined[:h, :] = depth_vis
        vis_combined[h:, :] = plane_vis
        
        print("âœ… åœ–åƒå¯è¦–åŒ–å®Œæˆ")
        return vis_combined


# å–®å…ƒæ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    # è¼‰å…¥é…ç½®
    with open("config.yaml", 'r') as f:
        config = yaml.safe_load(f)
    
    # åˆå§‹åŒ–å ´æ™¯ç†è§£æ¨¡çµ„
    scene_module = SceneUnderstanding("config.yaml")
    
    # æ¸¬è©¦å–®å¼µåœ–åƒ
    img_path = "test_image.png"
    if os.path.exists(img_path):
        img = cv2.imread(img_path)
        if img is not None:
            # è™•ç†åœ–åƒ
            results = scene_module.process_frame(img)
            
            # å¯è¦–åŒ–çµæœ
            vis_img = scene_module.visualize_results(img, results)
            
            # é¡¯ç¤ºçµæœ
            print("ğŸ–¼ï¸ æŒ‰ä»»æ„éµé—œé–‰è¦–çª—...")
            while True:
                cv2.imshow("Scene Understanding Results", vis_img)
                if cv2.waitKey(1) != -1:  # æœ‰ä»»ä½•æŒ‰éµ
                    break
            cv2.destroyAllWindows()
            
            print(f"æª¢æ¸¬åˆ° {len(results['planes'])} å€‹å¹³é¢")
            
            # ä¿å­˜çµæœ
            print("ğŸ’¾ æ­£åœ¨å„²å­˜çµæœ...")
            cv2.imwrite("scene_understanding_results.png", vis_img)
            print("âœ… å„²å­˜å®Œæˆï¼šscene_understanding_results.png")
        else:
            print(f"ç„¡æ³•è®€å–åœ–åƒ: {img_path}")
    else:
        print(f"åœ–åƒæª”æ¡ˆä¸å­˜åœ¨: {img_path}")
